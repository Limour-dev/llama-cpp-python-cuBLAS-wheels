name: Build GGML Wheels Small

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Version tag of llama-cpp-python to build: v0.1.78'
        default: 'v0.1.78'
        required: false
        type: string
  workflow_call:
    inputs:
      version:
        description: 'Version tag of llama-cpp-python to build: v0.1.78'
        default: 'v0.1.78'
        required: false
        type: string

permissions:
  contents: write

jobs:
  build_wheels:
    name: ${{ matrix.os }} ${{ matrix.pyver }} ${{ matrix.cuda }} ${{ matrix.releasetag == 'wheels' && 'AVX2' || matrix.releasetag }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [windows-latest]
        pyver: ["3.10", "3.11"]
        cuda: ["12.1.1", "12.2.0"]
        releasetag: ["wheels","AVX512"]
    defaults:
      run:
        shell: pwsh
    env:
      CUDAVER: ${{ matrix.cuda }}
      AVXVER: ${{ matrix.releasetag }}
      PCKGVER: ${{ inputs.version }}

    steps:
      - uses: actions/checkout@v4
        with:
          repository: 'abetlen/llama-cpp-python'
          ref: ${{ inputs.version }}
          submodules: 'recursive'
          
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.pyver }}
        
      - name: Setup Mamba
        uses: conda-incubator/setup-miniconda@v2.2.0
        with:
          activate-environment: "build"
          python-version: ${{ matrix.pyver }}
          miniforge-variant: Mambaforge
          miniforge-version: latest
          use-mamba: true
          add-pip-as-python-dependency: true
          auto-activate-base: false
          
      - name: Install Dependencies
        run: |
          $cudaVersion = $env:CUDAVER
          $cudaChannels = ''
          $cudaNum = [int]$cudaVersion.substring($cudaVersion.LastIndexOf('.')+1)
          while ($cudaNum -ge 0) { $cudaChannels += '-c nvidia/label/cuda-' + $cudaVersion.Remove($cudaVersion.LastIndexOf('.')+1) + $cudaNum + ' '; $cudaNum-- }
          mamba install -y 'cuda' $cudaChannels.TrimEnd().Split()
          python -m pip install build wheel
          
      - name: Change Package Name
        run: |
          $packageVersion = [version]$env:PCKGVER.TrimStart('v')
          $pyproject = Get-Content 'pyproject.toml' -raw
          $cmakelists = Get-Content 'CMakeLists.txt' -raw
          $regexstr = '(?s)(?<=\[project]\s+?name = ")llama_cpp_python(".+?all = \[\s+?")llama_cpp_python(\[.+?wheel.packages = \[")llama_cpp("].+?input = ")llama_cpp(?=/__init__.py")'
          $regexmatch = [Regex]::Matches($pyproject,$regexstr)
          if (!($regexmatch[0].Success)) {throw 'pyproject.toml parsing failed'}
          $newpyproject = $regexmatch[0].Result(('$`' + 'llama_cpp_python_cuda' + '$1llama_cpp_ggml$2' + 'llama_cpp_ggml$3llama_cpp_ggml' + '$'''))
          Copy-Item 'llama_cpp' 'llama_cpp_ggml' -recurse
          New-Item 'pyproject.toml' -itemType File -value $newpyproject -force
          New-Item 'CMakeLists.txt' -itemType File -value $cmakelists.Replace('llama_cpp','llama_cpp_ggml') -force
          $pyScripts = (Get-ChildItem $(Join-Path '.' 'llama_cpp_ggml' '*.py'))
          $pyScripts.fullname.foreach({New-Item $_ -itemType File -value (Get-Content $_ -raw).replace('import llama_cpp.llama','from . import llama') -force})
          
      - name: Build Wheel
        run: |
          $packageVersion = [version]$env:PCKGVER.TrimStart('v')
          $cudaVersion = $env:CUDAVER.Remove($env:CUDAVER.LastIndexOf('.')).Replace('.','')
          $env:CUDA_PATH = $env:CONDA_PREFIX
          $env:CUDA_HOME = $env:CONDA_PREFIX
          if ($IsLinux) {$env:LD_LIBRARY_PATH = $env:CONDA_PREFIX + '/lib:' + $env:LD_LIBRARY_PATH}
          $env:VERBOSE = '1'
          $env:FORCE_CMAKE = '1'
          $env:CMAKE_ARGS = '-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all'
          if ($packageVersion -gt [version]'0.2.13') {$env:CMAKE_ARGS = "-DLLAMA_NATIVE=off $env:CMAKE_ARGS"}
          if ($env:AVXVER -eq 'AVX') {$env:CMAKE_ARGS = $env:CMAKE_ARGS + ' -DLLAMA_AVX2=off -DLLAMA_FMA=off -DLLAMA_F16C=off'}
          if ($env:AVXVER -eq 'AVX512') {$env:CMAKE_ARGS = $env:CMAKE_ARGS + ' -DLLAMA_AVX512=on'}
          if ($env:AVXVER -eq 'basic') {$env:CMAKE_ARGS = $env:CMAKE_ARGS + ' -DLLAMA_AVX=off -DLLAMA_AVX2=off -DLLAMA_FMA=off -DLLAMA_F16C=off'}
          python -m build --wheel -C--build-option=egg_info "-C--build-option=--tag-build=+cu$cudaVersion"
          
      - name: Upload files to a GitHub release
        id: upload-release
        uses: svenstaro/upload-release-action@2.7.0
        continue-on-error: true
        with:
          file: ./dist/*.whl
          tag: ${{ matrix.releasetag }}
          file_glob: true
          make_latest: false
          overwrite: true
        
      - uses: actions/upload-artifact@v3
        if: steps.upload-release.outcome == 'failure'
        with:
          name: ${{ matrix.releasetag == 'wheels' && 'AVX2' || matrix.releasetag }}
          path: ./dist/*.whl